{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.感知机（perceptron）是根据输入实例的特征向量x对其进行二分类的线性分类模型\n",
    "$$f(x) = sign(w * x + b)$$\n",
    "  感知机模型对应于输入空间（特征空间）中的分离超平面$w * x + b = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.感知机学习的策略是极小化损失函数：\n",
    "  $$\\min_{w,b}L(a,b) = - \\sum_{x_i\\in M}y_i(w * x_i + b)$$\n",
    "  损失函数对应于误分类点到分离超平面的总距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.感知机学习算法是基于随机梯度下降的对损失函数的最优化算法，有原始形式和对偶形式。算法简单且易于实现。原始形式中，首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数。在这个过程中一次随机选取一个误分类点使其梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.当训练数据集线性可分时，感知机学习算法是收敛的。（Novikoff）\n",
    "  当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举例说明\n",
    "给定集合点以及label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = [[3,3],[4,3],[1,1]]\n",
    "y = [[1],[1],[-1]]\n",
    "w = [0,0]\n",
    "b = 0\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "w = np.array(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数 $$L(a,b) = - \\sum_{x_i\\in M}y_i(w * x_i + b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑一下损失函数的梯度\n",
    "$$\\nabla_wL(w,b) = - \\sum_{x_i\\in M}y_ix_i$$\n",
    "$$\\nabla_bL(w,b) = - \\sum_{x_i\\in M}y_i$$\n",
    "如果每次更新只选取一个点$(x_i,y_i)$\n",
    "那么更新公式就是\n",
    "$$w = w + \\eta y_ix_i$$\n",
    "$$b = b + \\eta y_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y,w,b,eta):\n",
    "    while True:\n",
    "        i = find_false(x,y,w,b)\n",
    "        if i is True:\n",
    "            break\n",
    "        w = w + eta*y[i]*x[i]\n",
    "        b = b + eta*y[i]\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_false(x,y,w,b):\n",
    "    for i in range(len(x)):\n",
    "        if y[i]*(np.dot(x[i],w) + b) <= 0:\n",
    "            return i\n",
    "    return True\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "[-3]\n"
     ]
    }
   ],
   "source": [
    "eta = 1\n",
    "w,b = train(x,y,w,b,eta)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑其对偶形式\n",
    "对偶形式的基本想法是，将$w$和$b$表示为实例$x_i$和$y_i$的线性组合的形式，通过求解其系数而求得$w$和$b$。$w$和$b$原更新公式：\n",
    "$$w = w + \\eta y_ix_i$$\n",
    "$$b = b + \\eta y_i$$\n",
    "逐步修改$w$和$b$,设修改$n$次，则$w$和$b$关于$(x_i,y_i)$的增量分别是$\\alpha_iy_ix_i$和$\\alpha_iy_i$，这里$\\alpha_i = n_i\\eta$ ,这样$w$和$b$也可以表示为\n",
    "$$w = \\sum_{i=1}^N\\alpha_iy_ix_i$$\n",
    "$$b = \\sum_{i=1}^N\\alpha_iy_i$$\n",
    "这里$\\alpha_i >=0,i=1,2,...N,当$\\ate = 1$时，表示第$i$个实例点由于误分而进行更新的次数。实例点更新次数越多，意味着它距离分离超平面越近，也就越难正确分类。换句话说，这样的实例对学习结果影响最大。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x) = sign(w \\cdot x + b) -->  f(x) = sign(\\sum_{j=1}^N\\alpha_iy_ix_i \\cdot x + b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义Gram矩阵 $$G = [x_i \\cdot x_j ]_{N\\times N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_false_dual(x,y,alpha,G,b):\n",
    "    for i in range(len(x)):\n",
    "        if y[i]*(sum(alpha[k] * y[k] * G[k][i] for k in range(len(G))) + b) <= 0:\n",
    "            return i\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dual(x,y,b,eta):\n",
    "    G = np.array(np.mat(x) * np.transpose(np.mat(x)))\n",
    "    alpha = np.zeros(len(x))\n",
    "    while True:\n",
    "        i = find_false_dual(x,y,alpha,G,b)\n",
    "        if i is True:\n",
    "            break\n",
    "        alpha[i] = alpha[i] + eta\n",
    "        b = b + eta*y[i]\n",
    "    return alpha,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 0. 5.]\n",
      "[1. 1.]\n",
      "[-3]\n"
     ]
    }
   ],
   "source": [
    "b = 0\n",
    "alpha,b = train_dual(x,y,b,eta)\n",
    "w = sum(alpha[i] * x[i] * y[i] for i in range(len(x)))\n",
    "print(alpha)\n",
    "print(w)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
